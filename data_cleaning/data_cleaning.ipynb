{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('D:\\\\Github\\\\financial_dashboard\\data_scrappers\\\\tweets.csv', index_col=0)\n",
    "# wsb_posts = pd.read_csv('D:\\\\Github\\\\financial_dashboard\\data_scrappers\\\\wsb_posts.csv')\n",
    "wsb_titles = pd.read_csv('D:\\\\Github\\\\financial_dashboard\\data_scrappers\\\\wsb_title.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.columns = ['Date','Ticker','Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('words')\n",
    "# words = set(nltk.corpus.words.words())\n",
    "\n",
    "def cleaner(tweet):\n",
    "    tweet = re.sub(r\"RT @[\\w]*:\",\"\",tweet)\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = re.sub(r\"[^a-zA-Z\\s]\",\"\",tweet)\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Remove Emojis\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \").replace('*','').replace('$','') #Remove hashtag sign but keep the text\n",
    "#     tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
    "#          if w.lower() in words or not w.isalpha())\n",
    "    return tweet\n",
    "\n",
    "# https://stackoverflow.com/questions/64719706/cleaning-twitter-data-pandas-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Tweet'] = tweets['Tweet'].map(lambda x: cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jacob\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wsb_titles['GME'].map(lambda x: cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in wsb_titles.columns:\n",
    "    wsb_titles[col] = wsb_titles[col].map(lambda x: np.nan if pd.isna(x)  else cleaner(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "# [analyzer.polarity_scores(x)['compound'] for x in tweets['Tweet'][:10]] \n",
    "\n",
    "def sentiment_df(df,col):\n",
    "\n",
    "    df['compund'] = [analyzer.polarity_scores(x)['compound'] for x in df[col]]\n",
    "    df['neg'] = [analyzer.polarity_scores(x)['neg'] for x in df[col]] \n",
    "    df['neu'] = [analyzer.polarity_scores(x)['neu'] for x in df[col]] \n",
    "    df['pos'] = [analyzer.polarity_scores(x)['pos'] for x in df[col]] \n",
    "\n",
    "    return df.drop(columns = col)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-f581433b1c2a>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['compund'] = [analyzer.polarity_scores(x)['compound'] for x in df[col]]\n",
      "<ipython-input-16-f581433b1c2a>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['neg'] = [analyzer.polarity_scores(x)['neg'] for x in df[col]]\n",
      "<ipython-input-16-f581433b1c2a>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['neu'] = [analyzer.polarity_scores(x)['neu'] for x in df[col]]\n",
      "<ipython-input-16-f581433b1c2a>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['pos'] = [analyzer.polarity_scores(x)['pos'] for x in df[col]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>compund</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-30 19:10:08</td>\n",
       "      <td>GME</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-30 12:45:00</td>\n",
       "      <td>GME</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-29 23:37:36</td>\n",
       "      <td>GME</td>\n",
       "      <td>-0.5574</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-01 05:37:05</td>\n",
       "      <td>GME</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-01 05:36:52</td>\n",
       "      <td>GME</td>\n",
       "      <td>0.7269</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date Ticker  compund    neg    neu    pos\n",
       "0  2021-03-30 19:10:08    GME   0.5719  0.000  0.802  0.198\n",
       "1  2021-03-30 12:45:00    GME   0.5106  0.000  0.699  0.301\n",
       "2  2021-03-29 23:37:36    GME  -0.5574  0.259  0.564  0.177\n",
       "3  2021-04-01 05:37:05    GME   0.0000  0.000  1.000  0.000\n",
       "4  2021-04-01 05:36:52    GME   0.7269  0.000  0.711  0.289"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df(tweets.head(),'Tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(wsb_titles, var_name='Ticker', value_name='Title').dropna() ## melts all the columns into one column and adds ticker column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193729, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.dropna().shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
